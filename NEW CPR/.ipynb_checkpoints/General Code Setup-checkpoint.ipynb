{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preperation\n",
    "\n",
    "this section takes data and prepares it for CPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## -BaseExtra-\n",
    "\n",
    "this module includes basic items used in preperation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testcheck(x, vset):\n",
    "    if type(pd.DataFrame()) == pd.core.frame.DataFrame\n",
    "        for v in vset.values:\n",
    "            if np.equal(x, v).all().all():\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestvector(target, A):\n",
    "    newv = [np.linalg.norm(np.array(np.array(target)-np.array(a))) for a in A]\n",
    "    return np.argmin(newv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthestvector(target, A):\n",
    "    newv = [np.linalg.norm(np.array(np.array(target)-np.array(a))) for a in A]\n",
    "    return np.argmax(newv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(x, a, v):\n",
    "    n = abs(x-a)*v\n",
    "    if a>x:\n",
    "        return x+n\n",
    "    elif a<x:\n",
    "        return x-n\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimove(X, A, v):\n",
    "    newvec = list()\n",
    "    for n, x in enumerate(X):\n",
    "        newvec.append(move(x, A[n], v))\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -DataPrepBase-\n",
    "\n",
    "this is for preparing data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crush(vector):\n",
    "    return [(v)/max(vector) for v in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(vector):\n",
    "    return (np.array(vector)/np.sum(vector)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -Prep-\n",
    "\n",
    "this is for preperation and as a branch to the other prep modules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import DataPrepBase\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(dataset):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    return pd.DataFrame(min_max_scaler.fit_transform(dataset.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Excecution\n",
    "\n",
    "this section takes the data and trains the cpr model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -Filter-\n",
    "\n",
    "This module filters the dataset given decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardFilterFunction(cluster_function, pick, data_set):\n",
    "    check = cluster_function.predict([pick])\n",
    "    return data_set[cluster_function.predict(data_set)==check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestFilterFunction(pick, data_set, cut = .50):\n",
    "    cutt = int(round(len(data_set)*cut, 0))\n",
    "    neigh = NearestNeighbors(n_neighbors=cutt)\n",
    "    neigh.fit(data_set)\n",
    "    return data_set.iloc[neigh.kneighbors([pick], cutt, return_distance=False)[0].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -Decision-\n",
    "\n",
    "this module takes decisions and uses it to train a prediction module"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import SimBot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleAveragePick(sets, cycles, target = 0):\n",
    "    picklist = list()\n",
    "    for c in range(cycles):\n",
    "        frm = [sets[n].iloc[a] for n, a in enumerate([random.randint(1,len(s)-1) for s in sets])]\n",
    "        for n, f in enumerate(frm):\n",
    "            print('---Choice '+str(n)+'---')\n",
    "            print(f)\n",
    "        pick = frm[int(input('Pick From Choices: '))]\n",
    "        picklist.append(pick)\n",
    "    return np.average(picklist, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -SimBot-\n",
    "\n",
    "this module simulates decisions based on a predetermined expected result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import BaseExtra\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleAveragePick(target, sets, cycles):\n",
    "    picklist = list()\n",
    "    for c in range(cycles):\n",
    "        frm = [sets[n].iloc[a] for n, a in enumerate([random.randint(1,len(s)-1) for s in sets])]\n",
    "        pick = frm[BaseExtra.closestvector(target, frm)]\n",
    "        picklist.append(pick)\n",
    "    return np.average(picklist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriangleMove(target, sets, cycles):\n",
    "    picklist = list()\n",
    "    start = np.average([np.average(s, axis=0) for s in sets], axis=0)\n",
    "    for c in range(cycles):\n",
    "        frm = [sets[n].iloc[a] for n, a in enumerate([random.randint(1,len(s)-1) for s in sets])]\n",
    "        close = frm[BaseExtra.closestvector(target, frm)]\n",
    "        far = frm[BaseExtra.farthestvector(target, frm)]\n",
    "        b = np.linalg.norm(np.array(far-close))/(np.linalg.norm(np.array(start-close))+np.linalg.norm(np.array(start-far)))\n",
    "        start = np.array(BaseExtra.multimove(start, close, b))\n",
    "    return start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## -Run-\n",
    "\n",
    "this module runs Cluster Choice Filtering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFilter(filter_function, pick, data_set, cluster_function = 0, cut = 0.50):\n",
    "    if filter_function == None:\n",
    "        raise Exception('Pick a data filter! available filters: hard, nearest')\n",
    "    elif filter_function == 'hard':\n",
    "        return Filter.hardFilterFunction(cluster_function, pick, data_set)\n",
    "    elif filter_function == 'nearest':\n",
    "        return Filter.nearestFilterFunction(pick, data_set, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionFunction(decision_function):\n",
    "    if decision_function == None:\n",
    "        raise Exception('Pick a decision function!')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_set, \n",
    "cycles_per_epoch=10,\n",
    "max_epochs=10, \n",
    "decision_function,\n",
    "cluster_function, \n",
    "filter_function, \n",
    "target_array = 0, \n",
    "n_clusters=2, \n",
    "minimum_cluster_size=10, \n",
    "maximum_cluster_size=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterChoiceFiltering(data_set,\n",
    "                           cycles_per_epoch=10,\n",
    "                           max_epochs=10,\n",
    "                           decision_function='simpleAveragePick',\n",
    "                           cluster_function='kMeans',\n",
    "                           filter_function='nearset',\n",
    "                           n_clusters=3,\n",
    "                           minimum_cluster_size=10,\n",
    "                           maximum_cluster_size=40,\n",
    "                           target_array=None\n",
    "                          ):\n",
    "    decision_function = decisionFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterChoiceFiltering(data_set,\n",
    "                           decision_function, \n",
    "                           cluster_function, \n",
    "                           filter_function='nearest', \n",
    "                           max_epochs, \n",
    "                           cycles_per_epoch = 0, \n",
    "                           target_array = 0, \n",
    "                           n_clusters=2, \n",
    "                           minimum_cluster_size=10, \n",
    "                           maximum_cluster_size=40\n",
    "                          ):\n",
    "    curset = data_set\n",
    "    cfunc = cluster_function(n_clusters = n_clusters)\n",
    "    cfunc.fit(curset)\n",
    "    echeck = 0\n",
    "    for e in range(max_epochs):\n",
    "        if len(curset)<maximum_cluster_size:\n",
    "            return curset, echeck\n",
    "        else:\n",
    "            if len(curset)>= n_clusters:\n",
    "                if min([len(curset[cfunc.predict(curset)==n]) for n in range(0, n_clusters)])<3:\n",
    "                    pass\n",
    "                else:\n",
    "                    if len(curset)<maximum_cluster_size:\n",
    "                        pass\n",
    "                    else:\n",
    "                        echeck+=1\n",
    "                        o = decision_function(target = target_array, sets = [curset[cfunc.predict(curset)==n] for n in range(0, n_clusters)], cycles = cycles_per_epoch)\n",
    "                        curset = dataFilter(filter_function = filter_function, cluster_function=cfunc, pick = o, data_set = curset)\n",
    "                        lastcurset = curset\n",
    "                        try:\n",
    "                            cfunc.fit(curset)\n",
    "                        except:\n",
    "                            return curset, echeck\n",
    "                        if len(curset)<minimum_cluster_size:\n",
    "                            return lastcurset, echeck\n",
    "    return curset, echeck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## -DeepRun-\n",
    "\n",
    "this module goes through all possible results with simbot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import Run\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterChoiceFiltering(decision_functions, \n",
    "    data_set, \n",
    "    cluster_function_list, \n",
    "    filter_function_list, \n",
    "    max_epochs, \n",
    "    cycles_per_epoch_list, \n",
    "    n_clusters_list, \n",
    "    minimum_cluster_size=10, \n",
    "    maximum_cluster_size=40,\n",
    "    showprogress = True):\n",
    "    check = list()\n",
    "    step = 0\n",
    "    with progressbar.ProgressBar(max_value=(len(data_set)*len(decision_functions)*len(cluster_function_list)*len(filter_function_list)*len(n_clusters_list)*len(cycles_per_epoch_list))) as bar:\n",
    "        for dfun in decision_functions:\n",
    "            for cfun in cluster_function_list:\n",
    "                for ffun in filter_function_list:\n",
    "                    for nclu in n_clusters_list:\n",
    "                        for ccyc in cycles_per_epoch_list:\n",
    "                            print([dfun, cfun, ffun, nclu, ccyc])\n",
    "                            for g in range(0,len(data_set)):\n",
    "                                if showprogress==True:\n",
    "                                    step+=1\n",
    "                                    bar.update(step)\n",
    "                                clust = Run.clusterChoiceFiltering(decision_function = dfun,\n",
    "                                    data_set = data_set, \n",
    "                                    target_array = data_set[g:g+1], \n",
    "                                    cluster_function = cfun, \n",
    "                                    filter_function = ffun, \n",
    "                                    max_epochs = max_epochs, \n",
    "                                    cycles_per_epoch = ccyc, \n",
    "                                    n_clusters = nclu, \n",
    "                                    minimum_cluster_size = minimum_cluster_size,\n",
    "                                    maximum_cluster_size = maximum_cluster_size)\n",
    "                                check.append([str(dfun), str(cfun), str(ffun), str(nclu), str(ccyc), data_set[g:g+1], clust[1], clust[0]])\n",
    "    return pd.DataFrame(check, columns=['Decision_Function', 'Cluster_Function', 'Filter', 'N_Clusters', 'Cycles', 'Item', 'Epochs', 'Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Diagnostics\n",
    "\n",
    "this section takes the cpr model and runs diagnosis on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -Graph-\n",
    "\n",
    "this module makes a "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternatespace(x, y):\n",
    "    group = list()\n",
    "    for a in range(y):\n",
    "        for b in range(x):\n",
    "            group.append([b, a])\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 1, 3, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiclustgraph(dataset, size=50):\n",
    "    a = len(dataset.columns)\n",
    "    fig, axs = plt.subplots(a, a, figsize=(size, size))\n",
    "    for c, t in enumerate(alternatespace(a, a)):\n",
    "        if t[0] == t[1]:\n",
    "            axs[t[0]][t[1]].hist(dataset[dataset.columns[[t[0]]]], color ='tab:blue', histtype = 'step', bins=100)\n",
    "            axs[t[0]][t[1]].title.set_text(dataset.columns[t[0]]+' vs. '+dataset.columns[t[1]])\n",
    "        else:\n",
    "            if t[0]>t[1]:\n",
    "                axs[t[0]][t[1]].scatter(dataset[dataset.columns[[t[0]]]],dataset[dataset.columns[t[1]]], color ='tab:blue')\n",
    "                axs[t[0]][t[1]].title.set_text(dataset.columns[t[0]]+' vs. '+dataset.columns[t[1]])\n",
    "                axs[t[0]][t[1]].set_xlabel(dataset.columns[t[0]])\n",
    "                axs[t[0]][t[1]].set_ylabel(dataset.columns[t[1]])\n",
    "            if t[0]<t[1]:\n",
    "                axs[t[0]][t[1]].scatter(dataset[dataset.columns[[t[0]]]],dataset[dataset.columns[t[1]]], color ='tab:orange')\n",
    "                axs[t[0]][t[1]].title.set_text(dataset.columns[t[0]]+' vs. '+dataset.columns[t[1]])\n",
    "                axs[t[0]][t[1]].set_xlabel(dataset.columns[t[0]])\n",
    "                axs[t[0]][t[1]].set_ylabel(dataset.columns[t[1]])\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosePlot(frame, columns):\n",
    "    for c in columns:\n",
    "        m = list(range(1, max(frame[c])+2))\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.title('Distribution of Total '+c, fontsize=20)\n",
    "        plt.xticks(m)\n",
    "        plt.xlabel('Total '+c)\n",
    "        plt.hist(frame[frame['Sucessful']==True][c], bins = m, align = 'left', stacked=True, label='Sucessful Test', color = 'blue')\n",
    "        plt.hist(frame[frame['Sucessful']==False][c], bins = m, align = 'left', stacked=True, label='Un-Sucessful Test', color = 'orange')\n",
    "        plt.legend()\n",
    "        plt.text(0, -20, 'Minimum '+c+': '+str(np.min(frame[c]))+' | Average '+c+': '+str(round(np.average(frame[c]), 1))+' | Maximum '+c+': '+str(np.max(frame[c])), fontsize=15)\n",
    "        plt.text(0, -40, 'Average '+c+': '+str(round(np.average(frame[c]), 1)), fontsize=15)\n",
    "        plt.text(0, -60, 'Maximum '+c+': '+str(np.max(frame[c])), fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## -Diagnose-\n",
    "\n",
    "this checks the results of a deep run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import Graph\n",
    "import BaseExtra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepVitals(DeepFull):\n",
    "    check = list()\n",
    "    for d in range(len(DeepFull)):\n",
    "        check.append([BaseExtra.testcheck(DeepFull[d:d+1]['Item'].iloc[0], DeepFull[d:d+1]['Cluster'].iloc[0]), DeepFull[d:d+1]['Epochs'].iloc[0], len(DeepFull[d:d+1]['Cluster'].iloc[0])])\n",
    "    checkframe = pd.DataFrame(check, columns=['Sucessful', 'Epochs', 'Cluster_Size'])\n",
    "    Graph.diagnosePlot(checkframe, ['Epochs', 'Cluster_Size'])\n",
    "    print(str(len(checkframe[checkframe['Sucessful']==True]))+' Sucessful out of '+str(len(checkframe))+\" (\"+str(round(len(checkframe[checkframe['Sucessful']==True])/len(checkframe), 3))+\")\")\n",
    "    return checkframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
